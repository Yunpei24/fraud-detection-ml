# Fraud Detection - Airflow Orchestration

Orchestration des pipelines ML avec Apache Airflow 2.7.0

## ðŸŽ¯ Vue d'ensemble

Airflow orchestre 3 pipelines critiques:
1. **DAG 01 - Training Pipeline**: EntraÃ®nement quotidien avec dÃ©cision intelligente
2. **DAG 02 - Drift Monitoring**: DÃ©tection horaire de drift (Data/Target/Concept)

## ðŸ“‹ PrÃ©-requis

- Docker & Docker Compose
- PostgreSQL (port 5432 pour fraud_db)
- 4GB RAM minimum pour Airflow

## ðŸš€ DÃ©marrage rapide

### 1. Configuration

```bash
cd fraud-detection-ml/airflow

# Copier le fichier .env
cp .env.example .env

# Modifier les variables (si nÃ©cessaire)
nano .env
```

### 2. Lancer Airflow

```bash
# DÃ©marrer tous les services
docker-compose -f docker-compose.airflow.yml up -d

# VÃ©rifier les logs
docker-compose -f docker-compose.airflow.yml logs -f airflow-scheduler
```

### 3. AccÃ©der au Web UI

- URL: http://localhost:8080
- Username: `airflow`
- Password: `airflow`

### 4. Activer les DAGs

Dans l'UI Airflow:
1. Aller sur **DAGs**
2. Activer `02_drift_monitoring` (critique)
3. Activer `01_training_pipeline`

## ðŸ“Š Architecture des DAGs

### DAG 02: Drift Monitoring (PRIORITÃ‰ #1)

**Schedule**: Toutes les heures (`0 * * * *`)

**Flow**:
```
run_drift_monitoring
    â†“
parse_drift_results
    â†“
decide_next_step (Branch)
    â”œâ†’ trigger_retraining_dag (si drift critique)
    â”œâ†’ send_drift_alert (si drift moyen)
    â””â†’ no_action (si pas de drift)
    â†“
save_drift_metrics
```

**DÃ©clenchement du retraining**:
- Concept drift dÃ©tectÃ© â†’ Retraining IMMÃ‰DIAT
- Data drift avec PSI > 0.5 â†’ Retraining HIGH priority
- Data drift avec PSI > 0.3 â†’ Retraining MEDIUM priority

### DAG 01: Training Pipeline

**Schedule**: Quotidien Ã  2h du matin (`0 2 * * *`)

**DÃ©cision intelligente**:
```python
# Ne retrain PAS si:
- DerniÃ¨re training < 48h (cooldown)
- Nouvelles transactions < 10,000
```

**Flow**:
```
check_should_retrain (dÃ©cision intelligente)
    â†“
decide_training_branch
    â”œâ†’ load_training_data â†’ train_databricks â†’ validate â†’ register
    â””â†’ skip_training
```

**Validation**:
- Recall minimum: 80%
- Precision minimum: 75%
- Si Ã©chec â†’ Alerte + Pas de promotion

## ðŸ”§ Configuration

### Variables d'environnement critiques

```bash
# Database fraud_db
FRAUD_DATABASE_URL=postgresql://postgres:postgres@postgres-fraud:5432/fraud_db

# MLflow tracking
MLFLOW_TRACKING_URI=http://mlflow:5000

# Databricks (training distribuÃ©)
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
DATABRICKS_TOKEN=your-token

# Thresholds
DATA_DRIFT_THRESHOLD=0.3
CONCEPT_DRIFT_THRESHOLD=0.05
MIN_RECALL_THRESHOLD=0.80
MIN_PRECISION_THRESHOLD=0.75
```

## ðŸ“ Structure

```
airflow/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ 01_training_pipeline.py       # Training quotidien
â”‚   â””â”€â”€ 02_drift_monitoring.py        # Drift horaire (CRITIQUE)
â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ operators/
â”‚       â”œâ”€â”€ mlflow_operator.py        # MLflow registration
â”‚       â””â”€â”€ alert_operator.py         # Fraud alerts
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                   # Pydantic settings
â”œâ”€â”€ docker-compose.airflow.yml        # Services Airflow
â”œâ”€â”€ Dockerfile                        # Image custom
â””â”€â”€ requirements.txt                  # DÃ©pendances
```

## ðŸ” Monitoring

### VÃ©rifier les DAGs

```bash
# Lister les DAGs
docker exec -it airflow-scheduler airflow dags list

# Tester un DAG
docker exec -it airflow-scheduler airflow dags test 02_drift_monitoring 2024-01-18
```

### Logs en temps rÃ©el

```bash
# Scheduler logs
docker-compose -f docker-compose.airflow.yml logs -f airflow-scheduler

# Webserver logs
docker-compose -f docker-compose.airflow.yml logs -f airflow-webserver
```

### Base de donnÃ©es

```bash
# VÃ©rifier les mÃ©triques de drift
docker exec -it postgres-fraud psql -U postgres -d fraud_db -c "SELECT * FROM drift_metrics ORDER BY detected_at DESC LIMIT 10;"

# VÃ©rifier les retraining triggers
docker exec -it postgres-fraud psql -U postgres -d fraud_db -c "SELECT * FROM retraining_triggers ORDER BY triggered_at DESC LIMIT 5;"
```

## ðŸ› Troubleshooting

### DAG n'apparaÃ®t pas dans l'UI

```bash
# VÃ©rifier les erreurs de parsing
docker exec -it airflow-scheduler airflow dags list-import-errors
```

### Connexion PostgreSQL Ã©chouÃ©e

```bash
# Tester la connexion depuis le scheduler
docker exec -it airflow-scheduler python -c "from airflow.config.settings import settings; print(settings.fraud_database_url)"
```

### Drift monitoring n'envoie pas d'alertes

```bash
# VÃ©rifier les logs du task
docker-compose -f docker-compose.airflow.yml logs airflow-scheduler | grep drift_monitoring
```

## ðŸ“ˆ MÃ©triques clÃ©s

### Tables PostgreSQL

1. **drift_metrics**: MÃ©triques de drift (PSI, recall, etc.)
2. **retraining_triggers**: Historique des retranings
3. **model_versions**: Versions MLflow enregistrÃ©es
4. **airflow_task_metrics**: Performance Airflow

### Dashboards recommandÃ©s

- Grafana: MÃ©triques Airflow (task duration, success rate)
- MLflow UI: ExpÃ©riences et modÃ¨les
- Airflow UI: DAG runs, task logs

## ðŸ”’ SÃ©curitÃ©

- Changer les passwords par dÃ©faut dans `.env`
- Utiliser Azure Key Vault pour DATABRICKS_TOKEN
- Activer l'authentification RBAC dans Airflow

## ðŸš¨ Alertes

Les alertes sont envoyÃ©es par `FraudDetectionAlertOperator`:
- Email: `ALERT_EMAIL_RECIPIENTS` dans `.env`
- Slack: Configurer webhook dans `config/settings.py`

## ðŸ“š Ressources

- [Airflow Docs](https://airflow.apache.org/docs/)
- [Databricks Provider](https://airflow.apache.org/docs/apache-airflow-providers-databricks/)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)
