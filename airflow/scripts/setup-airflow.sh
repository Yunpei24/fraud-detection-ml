#!/bin/bash

# Script de setup Airflow pour Fraud Detection
# Usage: ./setup-airflow.sh

set -e

echo "ðŸš€ Setup Airflow pour Fraud Detection"
echo "======================================"

# VÃ©rifier Docker
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker n'est pas installÃ©"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Compose n'est pas installÃ©"
    exit 1
fi

echo "âœ… Docker et Docker Compose installÃ©s"

# VÃ©rifier .env
if [ ! -f .env ]; then
    echo "ðŸ“ CrÃ©ation du fichier .env depuis .env.example"
    cp .env.example .env
    echo "âš ï¸  IMPORTANT: Modifier .env avec vos credentials"
    echo "   - DATABRICKS_HOST"
    echo "   - DATABRICKS_TOKEN"
    echo "   - ALERT_EMAIL_RECIPIENTS"
else
    echo "âœ… Fichier .env existe"
fi

# CrÃ©er les dossiers nÃ©cessaires
echo "ðŸ“ CrÃ©ation des dossiers"
mkdir -p logs dags plugins config scripts

# Set AIRFLOW_UID
echo "ðŸ”§ Configuration AIRFLOW_UID"
if [ -z "$AIRFLOW_UID" ]; then
    export AIRFLOW_UID=50000
    echo "export AIRFLOW_UID=50000" >> .env
fi
echo "âœ… AIRFLOW_UID=$AIRFLOW_UID"

# Initialiser la base de donnÃ©es Airflow
echo "ðŸ—„ï¸  Initialisation de la base de donnÃ©es Airflow"
docker-compose -f docker-compose.airflow.yml up airflow-init

# DÃ©marrer les services
echo "ðŸš€ DÃ©marrage des services Airflow"
docker-compose -f docker-compose.airflow.yml up -d

# Attendre que les services soient prÃªts
echo "â³ Attente que les services dÃ©marrent (30s)"
sleep 30

# VÃ©rifier l'Ã©tat des services
echo "ðŸ” VÃ©rification des services"
docker-compose -f docker-compose.airflow.yml ps

# VÃ©rifier les DAGs
echo "ðŸ“Š Liste des DAGs"
docker exec -it airflow-scheduler airflow dags list || echo "âš ï¸  DAGs pas encore chargÃ©s"

echo ""
echo "âœ… Setup terminÃ©!"
echo ""
echo "ðŸ“‹ Prochaines Ã©tapes:"
echo "1. AccÃ©der Ã  Airflow UI: http://localhost:8080"
echo "   - Username: airflow"
echo "   - Password: airflow"
echo ""
echo "2. Activer les DAGs dans l'UI:"
echo "   - 02_drift_monitoring (CRITIQUE)"
echo "   - 01_training_pipeline"
echo ""
echo "3. VÃ©rifier les logs:"
echo "   docker-compose -f docker-compose.airflow.yml logs -f airflow-scheduler"
echo ""
echo "4. Configurer les connexions Airflow:"
echo "   - Admin > Connections"
echo "   - Ajouter 'databricks_default' avec votre token"
echo ""
