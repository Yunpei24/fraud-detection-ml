name: CI/CD Pipeline

on:
  push:
    branches: [ develop, main ]
    paths:
      - 'api/**'
      - 'data/**'
      - 'drift/**'
      - 'training/**'
      - 'airflow/**'
      - 'mlflow/**'
      - 'common/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  pull_request:
    branches: [ develop, main ]
    paths:
      - 'api/**'
      - 'data/**'
      - 'drift/**'
      - 'training/**'
      - 'airflow/**'
      - 'mlflow/**'
      - 'common/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  workflow_dispatch:

env:
  REGISTRY: ${{ secrets.DOCKERHUB_USERNAME }}

jobs:
  # ==============================================================================
  # CODE QUALITY CHECKS
  # ==============================================================================

  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10"]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest pylint mypy bandit black isort safety

    - name: Run Black (code formatting)
      run: |
        black --check --diff . || (echo "Code is not formatted with Black. Run 'black .' to fix." && exit 1)

    # - name: Run isort (import sorting)
    #   run: |
    #     isort --check-only --diff . || (echo "Imports are not sorted. Run 'isort .' to fix." && exit 1)

    - name: Run Flake8 (linting)
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Run Bandit (security)
      run: |
        bandit -r . -f json -o bandit-report.json || true
        python -c "
        import json
        with open('bandit-report.json') as f:
            data = json.load(f)
        high_severity = [i for i in data.get('results', []) if i.get('issue_severity') == 'high']
        if high_severity:
            print(f'Found {len(high_severity)} high-severity security issues:')
            for issue in high_severity:
                print(f'  - {issue.get(\"filename\", \"unknown\")}:{issue.get(\"line_number\", \"?\")} - {issue.get(\"issue_text\", \"unknown\")}')
            exit(1)
        print('No high-severity security issues found.')
        "

    - name: Run Safety (vulnerability check)
      run: |
        safety check --full-report

    - name: Run MyPy (type checking)
      run: |
        mypy . --ignore-missing-imports --no-strict-optional || true

  # ==============================================================================
  # UNIT TESTS
  # ==============================================================================

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        python-version: ["3.10"]
        service: [api, data, drift, training]

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: fraud_user
          POSTGRES_PASSWORD: fraud_pass_dev_2024
          POSTGRES_DB: fraud_detection
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 3s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Free Disk Space (Ubuntu)
      if: matrix.service == 'training'
      uses: jlumbroso/free-disk-space@main
      with:
        # This might remove tools that are actually needed
        tool-cache: false
        # All of these default to true, but feel free to set to "false" if necessary
        android: true
        dotnet: true
        haskell: true
        large-packages: true
        docker-images: false
        swap-storage: true

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.service }}-${{ hashFiles(format('{0}/requirements*.txt', matrix.service)) }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.service }}-

    - name: Free up disk space (for training module)
      if: matrix.service == 'training'
      run: |
        # Remove unnecessary packages to free up space
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /opt/ghc
        sudo rm -rf /usr/local/share/boost
        sudo rm -rf "$AGENT_TOOLSDIRECTORY"
        sudo apt-get clean
        df -h

    - name: Install service dependencies
      run: |
        cd ${{ matrix.service }}
        # For training module, use lightweight test requirements
        if [ "${{ matrix.service }}" = "training" ]; then
          if [ -f requirements.test.txt ]; then
            echo "Installing training dependencies with CPU-only packages..."
            pip install -r requirements.test.txt
          else
            echo "requirements.test.txt not found, falling back to regular requirements.txt"
            pip install torch==2.4.1+cpu -f https://download.pytorch.org/whl/torch_stable.html || pip install torch==2.4.1
            pip install -r requirements.txt --no-deps
          fi
          pip install -r ../requirements.txt
        else
          pip install -r requirements.txt
          pip install -r ../requirements.txt
        fi

    - name: Install common package
      run: |
        cd common
        pip install -e .

    - name: Run unit tests with coverage
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: fraud_user
        POSTGRES_PASSWORD: fraud_pass_dev_2024
        POSTGRES_DB: fraud_detection
        REDIS_HOST: localhost
        REDIS_PORT: 6379
        SKIP_INTEGRATION_TESTS: "true"  # Skip integration tests that require full database setup
      run: |
        cd ${{ matrix.service }}
        python -m pytest tests/ -v --cov=. --cov-report=xml --cov-report=term-missing --cov-fail-under=30

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./${{ matrix.service }}/coverage.xml
        flags: ${{ matrix.service }}
        name: ${{ matrix.service }}-coverage

  # ==============================================================================
  # INTEGRATION TESTS
  # ==============================================================================

  # integration-tests:
  #   name: Integration Tests
  #   runs-on: ubuntu-latest
  #   needs: unit-tests

  #   services:
  #     postgres:
  #       image: postgres:15-alpine
  #       env:
  #         POSTGRES_USER: fraud_user
  #         POSTGRES_PASSWORD: fraud_pass_dev
  #         POSTGRES_DB: fraud_detection
  #       options: >-
  #         --health-cmd pg_isready
  #         --health-interval 10s
  #         --health-timeout 5s
  #         --health-retries 5
  #       ports:
  #         - 5432:5432

  #     redis:
  #       image: redis:7-alpine
  #       options: >-
  #         --health-cmd "redis-cli ping"
  #         --health-interval 10s
  #         --health-timeout 3s
  #         --health-retries 5
  #       ports:
  #         - 6379:6379

  #     mlflow:
  #       image: ghcr.io/mlflow/mlflow:v2.10.2
  #       env:
  #         MLFLOW_TRACKING_URI: http://localhost:5000
  #       ports:
  #         - 5000:5000

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Set up Python
  #     uses: actions/setup-python@v4
  #     with:
  #       python-version: "3.10"

  #   - name: Install Docker Compose
  #     run: |
  #       sudo apt-get update
  #       sudo apt-get install -y docker-compose

  #   - name: Run integration tests
  #     run: |
  #       # Start only essential services for integration tests
  #       docker-compose -f docker-compose.local.yml up -d postgres redis mlflow airflow api

  #       # Wait for services to be healthy
  #       timeout 300 bash -c 'until docker-compose -f docker-compose.local.yml ps | grep -q "healthy"; do sleep 5; done'

  #       # Run integration tests
  #       python -m pytest tests/integration/ -v --tb=short

  # ==============================================================================
  # DOCKER BUILD & PUSH
  # ==============================================================================

  docker-build:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    needs: [unit-tests] # [unit-tests, integration-tests]
    permissions:
      contents: read
      id-token: write
      attestations: write

    strategy:
      matrix:
        service: [api, data, drift, training, airflow, mlflow]
        include:
          - service: api
            context: .
            dockerfile: ./api/Dockerfile
            path_filter: 'api/**'
          - service: data
            context: .
            dockerfile: ./data/Dockerfile
            path_filter: 'data/**'
          - service: drift
            context: .
            dockerfile: ./drift/Dockerfile
            path_filter: 'drift/**'
          - service: training
            context: .
            dockerfile: ./training/Dockerfile
            path_filter: 'training/**'
          - service: airflow
            context: .
            dockerfile: ./airflow/Dockerfile
            path_filter: 'airflow/**'
          - service: mlflow
            context: .
            dockerfile: ./mlflow/Dockerfile
            path_filter: 'mlflow/**'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Necessary to compare changes

    - name: Free up Docker space on runner
      run: |
        echo "Pruning docker system and builder to free space..."
        docker system prune -af || true
        docker builder prune -af --filter until=24h || true

    - name: Check if service was modified
      id: check_changes
      run: |
        # Build all services if:
        # 1. Push to main branch
        # 2. Pull request (for testing)
        # 3. CI/CD workflow file was modified
        SERVICE_MODIFIED=false
        
        # Check if this is a push to main or a pull request
        if [ "${{ github.ref }}" = "refs/heads/main" ] || [ "${{ github.event_name }}" = "pull_request" ]; then
          echo "Building all services (main branch or pull request)"
          SERVICE_MODIFIED=true
        else
          # Get the list of modified files
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }})
          else
            CHANGED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }})
          fi
          
          echo "Changed files:"
          echo "$CHANGED_FILES"
          
          # Check if CI/CD workflow was modified (build all services)
          if echo "$CHANGED_FILES" | grep -q "^\.github/workflows/ci-cd\.yml"; then
            echo "CI/CD workflow modified - building all services"
            SERVICE_MODIFIED=true
          # Check if the current service was modified
          elif echo "$CHANGED_FILES" | grep -q "^${{ matrix.service }}/"; then
            SERVICE_MODIFIED=true
          # Check if common/ or requirements.txt were modified (affects all services)
          elif echo "$CHANGED_FILES" | grep -qE "^common/|^requirements\.txt"; then
            SERVICE_MODIFIED=true
          # Check if the service's Dockerfile was modified
          elif echo "$CHANGED_FILES" | grep -q "^${{ matrix.service }}/Dockerfile"; then
            SERVICE_MODIFIED=true
          fi
        fi
        
        echo "service_modified=$SERVICE_MODIFIED" >> $GITHUB_OUTPUT
        echo "Service ${{ matrix.service }} modified: $SERVICE_MODIFIED"

    # Setup QEMU for Multi-Architectures builds
    - name: Set up QEMU
      if: steps.check_changes.outputs.service_modified == 'true'
      uses: docker/setup-qemu-action@v3
      with:
        platforms: linux/amd64,linux/arm64

    - name: Set up Docker Buildx
      if: steps.check_changes.outputs.service_modified == 'true'
      uses: docker/setup-buildx-action@v3

    - name: Log in to Docker Hub
      if: steps.check_changes.outputs.service_modified == 'true' && github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}

    - name: Extract metadata
      if: steps.check_changes.outputs.service_modified == 'true'
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      if: steps.check_changes.outputs.service_modified == 'true'
      id: build
      uses: docker/build-push-action@v5
      with:
        context: ${{ matrix.context }}
        file: ${{ matrix.dockerfile }}
        platforms: linux/amd64,linux/arm64
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        provenance: false  # Disable provenance attestations for compatibility

    - name: Generate artifact attestation
      if: steps.check_changes.outputs.service_modified == 'true' && github.event_name != 'pull_request'
      uses: actions/attest-build-provenance@v1
      with:
        subject-name: ${{ env.REGISTRY }}/${{ matrix.service}}
        subject-digest: ${{ steps.build.outputs.digest }}
        push-to-registry: false
    
    - name: Skip message
      if: steps.check_changes.outputs.service_modified == 'false'
      run: |
        echo " Skipping build for ${{ matrix.service }} - no changes detected"

  # ==============================================================================
  # DEPLOYMENT TO STAGING (Azure Container Instances)
  # ==============================================================================

  # deploy-staging:
  #   name: Deploy to Staging
  #   runs-on: ubuntu-latest
  #   needs: docker-build
  #   if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
  #   environment: staging

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Azure Login
  #     uses: azure/login@v1
  #     with:
  #       creds: ${{ secrets.AZURE_CREDENTIALS }}

  #   - name: Deploy to Azure Container Instances (Staging)
  #     uses: azure/aci-deploy@v1
  #     with:
  #       resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
  #       dns-name-label: fraud-detection-staging
  #       image: ${{ env.REGISTRY }}/api:develop
  #       name: fraud-detection-api-staging
  #       location: ${{ secrets.AZURE_LOCATION }}
  #       ports: 8000
  #       environment-variables: |
  #         ENVIRONMENT=staging
  #         POSTGRES_HOST=${{ secrets.DB_HOST_STAGING }}
  #         POSTGRES_PORT=5432
  #         POSTGRES_DB=fraud_detection
  #         POSTGRES_USER=${{ secrets.DB_USER_STAGING }}
  #         POSTGRES_PASSWORD=${{ secrets.DB_PASSWORD_STAGING }}
  #         REDIS_HOST=${{ secrets.REDIS_HOST_STAGING }}
  #         REDIS_PORT=6379
  #         MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI_STAGING }}
  #         AZURE_STORAGE_CONNECTION_STRING=${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}

  #   - name: Run health checks
  #     run: |
  #       # Wait for service to be healthy
  #       timeout 600 bash -c '
  #       while true; do
  #         if curl -f -s http://fraud-detection-staging.${{ secrets.AZURE_LOCATION }}.azurecontainer.io:8000/health > /dev/null; then
  #           echo "Service is healthy"
  #           break
  #         fi
  #         echo "Waiting for service to be healthy..."
  #         sleep 30
  #       done
  #       '

  #   - name: Run smoke tests
  #     run: |
  #       # Run basic smoke tests against staging
  #       python -m pytest tests/smoke/ -v --tb=short \
  #         --api-url=http://fraud-detection-staging.${{ secrets.AZURE_LOCATION }}.azurecontainer.io:8000

  # ==============================================================================
  # DEPLOYMENT TO PRODUCTION (Azure Container Instances)
  # ==============================================================================

  # deploy-production:
  #   name: Deploy to Production
  #   runs-on: ubuntu-latest
  #   needs: deploy-staging
  #   if: github.ref == 'refs/heads/main' && github.event_name == 'push'
  #   environment: production

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Azure Login
  #     uses: azure/login@v1
  #     with:
  #       creds: ${{ secrets.AZURE_CREDENTIALS }}

  #   - name: Deploy API to Azure Container Instances (Production)
  #     uses: azure/aci-deploy@v1
  #     with:
  #       resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
  #       dns-name-label: fraud-detection-prod
  #       image: ${{ env.REGISTRY }}/api:latest
  #       name: fraud-detection-api-prod
  #       location: ${{ secrets.AZURE_LOCATION }}
  #       ports: 8000
  #       environment-variables: |
  #         ENVIRONMENT=production
  #         POSTGRES_HOST=${{ secrets.DB_HOST_PRODUCTION }}
  #         POSTGRES_PORT=5432
  #         POSTGRES_DB=fraud_detection
  #         POSTGRES_USER=${{ secrets.DB_USER_PRODUCTION }}
  #         POSTGRES_PASSWORD=${{ secrets.DB_PASSWORD_PRODUCTION }}
  #         REDIS_HOST=${{ secrets.REDIS_HOST_PRODUCTION }}
  #         REDIS_PORT=6379
  #         MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI_PRODUCTION }}
  #         AZURE_STORAGE_CONNECTION_STRING=${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}

  #   - name: Deploy Data Service to Azure Container Instances (Production)
  #     uses: azure/aci-deploy@v1
  #     with:
  #       resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
  #       dns-name-label: fraud-detection-data-prod
  #       image: ${{ env.REGISTRY }}/data:latest
  #       name: fraud-detection-data-prod
  #       location: ${{ secrets.AZURE_LOCATION }}
  #       ports: 8001
  #       environment-variables: |
  #         ENVIRONMENT=production
  #         POSTGRES_HOST=${{ secrets.DB_HOST_PRODUCTION }}
  #         POSTGRES_PORT=5432
  #         POSTGRES_DB=fraud_detection
  #         POSTGRES_USER=${{ secrets.DB_USER_PRODUCTION }}
  #         POSTGRES_PASSWORD=${{ secrets.DB_PASSWORD_PRODUCTION }}
  #         AZURE_STORAGE_CONNECTION_STRING=${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}

  #   - name: Deploy Drift Monitoring to Azure Container Instances (Production)
  #     uses: azure/aci-deploy@v1
  #     with:
  #       resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
  #       dns-name-label: fraud-detection-drift-prod
  #       image: ${{ env.REGISTRY }}/drift:latest
  #       name: fraud-detection-drift-prod
  #       location: ${{ secrets.AZURE_LOCATION }}
  #       ports: 8002
  #       environment-variables: |
  #         ENVIRONMENT=production
  #         POSTGRES_HOST=${{ secrets.DB_HOST_PRODUCTION }}
  #         POSTGRES_PORT=5432
  #         POSTGRES_DB=fraud_detection
  #         POSTGRES_USER=${{ secrets.DB_USER_PRODUCTION }}
  #         POSTGRES_PASSWORD=${{ secrets.DB_PASSWORD_PRODUCTION }}
  #         AZURE_STORAGE_CONNECTION_STRING=${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}

  #   - name: Deploy MLflow to Azure Container Instances (Production)
  #     uses: azure/aci-deploy@v1
  #     with:
  #       resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
  #       dns-name-label: fraud-detection-mlflow-prod
  #       image: ${{ env.REGISTRY }}/mlflow:latest
  #       name: fraud-detection-mlflow-prod
  #       location: ${{ secrets.AZURE_LOCATION }}
  #       ports: 5000
  #       environment-variables: |
  #         ENVIRONMENT=production
  #         POSTGRES_HOST=${{ secrets.DB_HOST_PRODUCTION }}
  #         POSTGRES_PORT=5432
  #         POSTGRES_DB=mlflow_db
  #         POSTGRES_USER=${{ secrets.DB_USER_PRODUCTION }}
  #         POSTGRES_PASSWORD=${{ secrets.DB_PASSWORD_PRODUCTION }}
  #         MLFLOW_DEFAULT_ARTIFACT_ROOT=${{ secrets.MLFLOW_DEFAULT_ARTIFACT_ROOT_PRODUCTION }}

  #   - name: Deploy Airflow Webserver to Azure Container Instances (Production)
  #     uses: azure/aci-deploy@v1
  #     with:
  #       resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}
  #       dns-name-label: fraud-detection-airflow-prod
  #       image: ${{ env.REGISTRY }}/airflow:latest
  #       name: fraud-detection-airflow-prod
  #       location: ${{ secrets.AZURE_LOCATION }}
  #       ports: 8080
  #       environment-variables: |
  #         ENVIRONMENT=production
  #         AIRFLOW__CORE__EXECUTOR=LocalExecutor
  #         AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${{ secrets.DB_USER_PRODUCTION }}:${{ secrets.DB_PASSWORD_PRODUCTION }}@${{ secrets.DB_HOST_PRODUCTION }}:5432/fraud_detection
  #         AIRFLOW__CORE__FERNET_KEY=${{ secrets.AIRFLOW_FERNET_KEY }}
  #         AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
  #         AIRFLOW__CORE__LOAD_EXAMPLES=false
  #         AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
  #         AIRFLOW__WEBSERVER__SECRET_KEY=${{ secrets.AIRFLOW_SECRET_KEY }}
  #         DOCKER_REGISTRY=${{ env.REGISTRY }}
  #         DOCKER_NETWORK=fraud-detection-network
  #         MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI_PRODUCTION }}
  #         ALERT_EMAIL=${{ secrets.ALERT_EMAIL }}
  #         AZURE_STORAGE_CONNECTION_STRING=${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
  #         PYTHONPATH=/opt/airflow:/opt/airflow/config:/opt/airflow/plugins

  #   - name: Run health checks
  #     run: |
  #       # Wait for services to be healthy
  #       timeout 600 bash -c '
  #       while true; do
  #         if curl -f -s http://fraud-detection-prod.${{ secrets.AZURE_LOCATION }}.azurecontainer.io:8000/health > /dev/null; then
  #           echo "API service is healthy"
  #           break
  #         fi
  #         echo "Waiting for API service to be healthy..."
  #         sleep 30
  #       done
  #       '

  #   - name: Run smoke tests
  #     run: |
  #       # Run basic smoke tests against production
  #       python -m pytest tests/smoke/ -v --tb=short \
  #         --api-url=http://fraud-detection-prod.${{ secrets.AZURE_LOCATION }}.azurecontainer.io:8000

  #   - name: Notify deployment success
  #     if: success()
  #     run: |
  #       # Send notification (Azure DevOps,s Teams, etc.)
  #       echo "Deployment to production successful"

  #   - name: Notify deployment failure
  #   if: failure()
  #     run: |
  #       # Send notification about deployment failure
  #       echo "Deployment to production failed"