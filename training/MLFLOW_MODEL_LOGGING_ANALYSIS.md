# üîç Analyse : MLflow Model Logging pour 4 Types de Mod√®les

**Date :** 4 novembre 2025  
**Fichier analys√© :** `training/src/mlflow_utils/tracking.py`  
**Fonction :** `log_model()`

---

## üìä R√©sum√© des 4 Mod√®les Entra√Æn√©s

| Mod√®le | Classe Wrapper | Classe R√©elle (`.model`) | Type | M√©thodes |
|--------|---------------|-------------------------|------|----------|
| **XGBoost** | `XGBoostModel` | `xgb.XGBClassifier` | Classifieur | `.predict()`, `.predict_proba()` |
| **Random Forest** | `RandomForestModel` | `sklearn.RandomForestClassifier` | Classifieur | `.predict()`, `.predict_proba()` |
| **Neural Network** | `NeuralNetworkModel` | `sklearn.MLPClassifier` | Classifieur | `.predict()`, `.predict_proba()` |
| **Isolation Forest** | `IsolationForestModel` | `sklearn.IsolationForest` | **Anomaly Detector** | `.predict()`, `.decision_function()` |

---

## üéØ Logique de `log_model()` dans `tracking.py`

```python
def log_model(model, artifact_path="model"):
    est = _unwrap_model(model)  # Extrait .model de nos wrappers
    
    if isinstance(est, xgb.XGBClassifier):
        # CAS 1: XGBoost ‚Üí mlflow.xgboost.log_model()
        mlflow.xgboost.log_model(est, artifact_path)
    else:
        # CAS 2: Tous les autres ‚Üí mlflow.sklearn.log_model()
        mlflow.sklearn.log_model(est, artifact_path)
```

---

## ‚úÖ Compatibilit√© par Mod√®le

### 1. **XGBoost** ‚úÖ PARFAIT
- **Type r√©el :** `xgb.XGBClassifier`
- **Logique MLflow :** `mlflow.xgboost.log_model()`
- **Status :** ‚úÖ Fonctionne parfaitement
- **Raison :** MLflow a un support natif pour XGBoost

### 2. **Random Forest** ‚úÖ PARFAIT
- **Type r√©el :** `sklearn.ensemble.RandomForestClassifier`
- **Logique MLflow :** `mlflow.sklearn.log_model()`
- **Status :** ‚úÖ Fonctionne parfaitement
- **Raison :** Classifieur sklearn standard

### 3. **Neural Network** ‚úÖ PARFAIT
- **Type r√©el :** `sklearn.neural_network.MLPClassifier`
- **Logique MLflow :** `mlflow.sklearn.log_model()`
- **Status :** ‚úÖ Fonctionne parfaitement
- **Raison :** Classifieur sklearn standard

### 4. **Isolation Forest** ‚úÖ FONCTIONNE (mais avec particularit√©s)
- **Type r√©el :** `sklearn.ensemble.IsolationForest`
- **Logique MLflow :** `mlflow.sklearn.log_model()`
- **Status :** ‚úÖ Fonctionne MAIS ce n'est pas un classifieur standard
- **Particularit√©s :**
  - N'a PAS `.predict_proba()` ‚Üí retourne un score via `.decision_function()`
  - `.predict()` retourne -1 (anomalie) ou 1 (normal), pas 0/1
  - MLflow le sauvegarde quand m√™me car c'est un estimateur sklearn valide

---

## üêõ Probl√®me Potentiel : Isolation Forest

**Pourquoi c'est diff√©rent ?**

L'Isolation Forest est un **anomaly detector**, pas un classifieur binaire standard :

| Aspect | Classifieurs (XGB, RF, NN) | Isolation Forest |
|--------|---------------------------|------------------|
| Type | Classification supervis√©e | D√©tection d'anomalies |
| Entra√Ænement | N√©cessite labels (0/1) | Peut √™tre non-supervis√© |
| Pr√©diction | `.predict_proba()` ‚Üí [0.0-1.0] | `.decision_function()` ‚Üí score |
| Sortie `.predict()` | 0 (normal) ou 1 (fraud) | -1 (anomalie) ou 1 (normal) |
| Interpr√©tation | Probabilit√© de fraude | Score d'anomalie (plus bas = plus anormal) |

**Dans notre code :**

```python
# training/src/models/isolation_forest.py
def predict_proba(self, X, y=None):
    """Custom predict_proba using decision_function scores"""
    scores = self.model.decision_function(X)
    # Convert anomaly scores to probabilities (lower = more anomalous = higher fraud prob)
    fraud_probs = 1 / (1 + np.exp(scores))  # Sigmoid transformation
    return np.column_stack((1 - fraud_probs, fraud_probs))
```

Nous avons **cr√©√© une m√©thode `.predict_proba()` custom** qui transforme les scores d'anomalie en probabilit√©s !

---

## üîß Am√©liorations Apport√©es

### Avant (code original) :
```python
except Exception:
    pass  # ‚ùå √âchoue silencieusement, impossible de d√©bugger !
```

### Apr√®s (code am√©lior√©) :
```python
except Exception as e:
    logger.error(f"‚ùå Failed to log model with mlflow: {e}")
    logger.error(f"   Model type: {model_class}")
    logger.error(f"   Model attributes: {dir(est)[:10]}...")
    
    # Fallback: log as pickle
    try:
        dump(est, "model.joblib")
        mlflow.log_artifacts(dump_dir, artifact_path)
        logger.info(f"‚úÖ Model artifacts logged successfully (fallback)")
    except Exception as e2:
        logger.error(f"‚ùå Fallback also failed: {e2}")
        raise RuntimeError(f"Failed to log model: {e}") from e2
```

### B√©n√©fices :
1. **Logs d√©taill√©s** : On voit exactement quelle erreur se produit
2. **Type de mod√®le** : On sait quel mod√®le √©choue
3. **Attributs** : On peut d√©bugger les m√©thodes manquantes
4. **Fallback robuste** : Si MLflow √©choue, on sauvegarde en pickle
5. **Raise exception** : Ne masque plus les erreurs critiques

---

## üß™ Tests √† Effectuer

### 1. V√©rifier que les 4 mod√®les se loggent correctement

```bash
# D√©clencher le training via Airflow UI
http://localhost:8080
# DAG: 01_training_pipeline

# Surveiller les logs
docker logs -f fraud-airflow-worker | grep "log_model"
```

**Logs attendus :**
```
Logging XGBoost model to artifact_path='model'
‚úÖ XGBoost model logged successfully

Logging sklearn model (RandomForestClassifier) to artifact_path='model'
‚úÖ Sklearn model (RandomForestClassifier) logged successfully

Logging sklearn model (MLPClassifier) to artifact_path='model'
‚úÖ Sklearn model (MLPClassifier) logged successfully

Logging sklearn model (IsolationForest) to artifact_path='model'
‚úÖ Sklearn model (IsolationForest) logged successfully
```

### 2. V√©rifier que les artifacts existent dans MLflow

```bash
# Lister les runs
docker exec fraud-training python -c "
import mlflow
mlflow.set_tracking_uri('http://mlflow:5000')
runs = mlflow.search_runs(experiment_names=['fraud_detection_training'])
print(f'Total runs: {len(runs)}')

# Check artifacts for latest run
if len(runs) > 0:
    run_id = runs.iloc[0]['run_id']
    client = mlflow.MlflowClient()
    artifacts = client.list_artifacts(run_id)
    print(f'Artifacts: {[a.path for a in artifacts]}')
"
```

**R√©sultat attendu :**
```
Total runs: 12  # (4 train + 4 eval + 4 register)
Artifacts: ['model', 'xgboost_metadata.json']
```

### 3. V√©rifier que les mod√®les sont dans le Registry

```bash
docker exec fraud-training python -c "
import mlflow
mlflow.set_tracking_uri('http://mlflow:5000')

client = mlflow.MlflowClient()
models = client.search_registered_models()

for model in models:
    print(f'Model: {model.name}')
    versions = client.search_model_versions(f\"name='{model.name}'\")
    for v in versions:
        print(f'  Version {v.version}: {v.current_stage}')
"
```

**R√©sultat attendu :**
```
Model: fraud_detection_xgboost
  Version 1: Staging
Model: fraud_detection_random_forest
  Version 1: Staging
Model: fraud_detection_neural_network
  Version 1: Staging
Model: fraud_detection_isolation_forest
  Version 1: Staging
```

---

## üìã Conclusion

### ‚úÖ Points Positifs
1. **Tous les 4 mod√®les sont support√©s** par la fonction `log_model()`
2. **XGBoost** a un traitement sp√©cial avec `mlflow.xgboost.log_model()`
3. **Les 3 autres mod√®les** utilisent `mlflow.sklearn.log_model()` qui fonctionne pour tous les estimateurs sklearn
4. **Isolation Forest** fonctionne car nous avons une m√©thode `.predict_proba()` custom dans le wrapper
5. **Logs d√©taill√©s** ajout√©s pour faciliter le debugging

### üîß Am√©liorations Apport√©es
1. Ajout de `logger` pour tracer les op√©rations MLflow
2. Messages d√©taill√©s pour chaque type de mod√®le
3. Fallback robuste vers pickle/joblib si MLflow √©choue
4. Raise des exceptions au lieu de les avaler silencieusement
5. Logs des attributs du mod√®le en cas d'erreur

### üöÄ Prochaine √âtape
**D√©clencher le training via Airflow UI et observer les logs d√©taill√©s !**

---

**Fichiers modifi√©s :**
- `training/src/mlflow_utils/tracking.py` (fonction `log_model()`)

**Documentation connexe :**
- `WHERE_ARE_MODELS_STORED.md` - Localisation des mod√®les apr√®s training
- `WHERE_ARE_MODELS_AFTER_TRAINING.md` - Flow complet de training ‚Üí deployment
